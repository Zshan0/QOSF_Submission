{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qosf_task2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5YE9ZAkUfhW"
      },
      "source": [
        "https://www.notion.so/zshan0notes/Task-2-Report-51e7f9db08664545a5b9f6bb5274cf30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvXv_EYlIV9V"
      },
      "source": [
        "# QOSF Task 2 $\\rightarrow$ Constructing a classifier\n",
        "\n",
        "## Problem statement\n",
        "To train a quantum variational circuit that will serve as a 4 bit map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty2XiPclO7_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108715e3-4e19-4a4c-d534-29aa78041538"
      },
      "source": [
        "try:\n",
        "    import pennylane as qml\n",
        "    from pennylane import numpy as np\n",
        "    from pennylane.optimize import NesterovMomentumOptimizer\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.style.use('seaborn-whitegrid')\n",
        "except:\n",
        "    !pip install pennylane  \n",
        "    import pennylane as qml\n",
        "    from pennylane import numpy as np\n",
        "    from pennylane.optimize import NesterovMomentumOptimizer\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.style.use('seaborn-whitegrid')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.18.0-py3-none-any.whl (631 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 33.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51 kB 34.4 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 61 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71 kB 33.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 92 kB 35.3 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 112 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 122 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 143 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 153 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 174 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 184 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 204 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 215 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 225 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 235 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 245 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 256 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 266 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 286 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 307 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 327 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 337 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 348 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 358 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 368 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 378 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 389 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 399 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 409 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 419 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 430 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 440 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 450 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 460 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 471 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 481 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 491 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 501 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 512 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 522 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 532 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 542 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 552 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 563 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 573 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 583 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 593 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 604 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 614 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 624 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 631 kB 37.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: autograd in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.3)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pennylane) (2.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.1)\n",
            "Collecting autoray\n",
            "  Downloading autoray-0.2.5-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.19.5)\n",
            "Collecting pennylane-lightning>=0.18\n",
            "  Downloading PennyLane_Lightning-0.18.0-cp37-cp37m-manylinux2010_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 36.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pennylane) (0.10.2)\n",
            "Collecting semantic-version==2.6\n",
            "  Downloading semantic_version-2.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from pennylane) (4.2.2)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->pennylane) (0.16.0)\n",
            "Installing collected packages: semantic-version, pennylane-lightning, autoray, pennylane\n",
            "Successfully installed autoray-0.2.5 pennylane-0.18.0 pennylane-lightning-0.18.0 semantic-version-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LomgdK7IIxbR"
      },
      "source": [
        "$$\n",
        "map(\\text{input_state}[i]) = \\text{output_state}[i]\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlmzN5OymLpy"
      },
      "source": [
        "## Setting random quantum states\n",
        "$$\n",
        "|0000\\rangle \\rightarrow |0011\\rangle \\\\\n",
        "|0001\\rangle \\rightarrow |0101\\rangle \\\\\n",
        "|0010\\rangle \\rightarrow |1010\\rangle \\\\\n",
        "|0011\\rangle \\rightarrow |1100\\rangle \\\\\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq_tlkc5IcUs"
      },
      "source": [
        "input_states = np.array([[0, 0, 0, 0],[0, 0, 0, 1],[0, 0, 1, 0], [0, 0, 1, 1]])\n",
        "output_states = np.array([[0, 0, 1, 1],[0, 1, 0, 1],[1, 0, 1, 0], [1, 1, 0, 0]])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MysRDZfIJ6b8"
      },
      "source": [
        "For making the classification more distinct will transform the target bits into:\n",
        "$$\n",
        "    0 \\rightarrow -1\\\\\n",
        "    1 \\rightarrow 1\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBmsG9iqZZW7"
      },
      "source": [
        "def Y_transform(y):\n",
        "    return 2 * y - 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-YMglyhJNvg"
      },
      "source": [
        "dev = qml.device(\"default.qubit\", wires=4)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_RdGUhLL1uJ"
      },
      "source": [
        "Setting 3 layers of gates with a rotation followed by CNOTS and another layer of rotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqix8Ux8JSW_"
      },
      "source": [
        "def layer(W):\n",
        "    # each rotation matrix takes in 3 inputs (phi, theta, omega)\n",
        "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
        "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
        "    qml.Rot(W[2, 0], W[2, 1], W[2, 2], wires=2)\n",
        "    qml.Rot(W[3, 0], W[3, 1], W[3, 2], wires=3)\n",
        "\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    qml.CNOT(wires=[1, 2])\n",
        "    qml.CNOT(wires=[2, 3])\n",
        "    qml.CNOT(wires=[3, 0])\n",
        "    \n",
        "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
        "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
        "    qml.Rot(W[2, 0], W[2, 1], W[2, 2], wires=2)\n",
        "    qml.Rot(W[3, 0], W[3, 1], W[3, 2], wires=3)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug7m1lPmJT-6"
      },
      "source": [
        "def statepreparation(x):\n",
        "    qml.BasisState(x, wires=[0, 1, 2, 3])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsckoCq3R1Aj"
      },
      "source": [
        "## Circuit\n",
        "The circuit at the end will have to do a measurement to convert the states into classical bits so that the loss can be calculated\n",
        "\n",
        "we apply `PauliZ` on all the qubits and then return the expected value on the observable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxtUa_f_Jrnp"
      },
      "source": [
        "def circuit(weights, x):\n",
        "    statepreparation(x)\n",
        "\n",
        "    # weights is a matrix\n",
        "    for W in weights:\n",
        "        layer(W)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klEoUZOtKAt4"
      },
      "source": [
        "@qml.qnode(dev)\n",
        "def variational_classifier(var, x):\n",
        "    weights = var\n",
        "    circuit(weights, x) \n",
        "    return [qml.expval(qml.PauliZ(x)) for x in range(4)] # because 1 and -1 "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2k_7P1PNtUl"
      },
      "source": [
        "## Loss\n",
        "Mean Squared Error between the expected and the output is set to be the loss\n",
        "\n",
        "## Accuracy\n",
        "Accuracy is the number of correct predictions with a small margin of error\n",
        "\n",
        "## Cost\n",
        "The cost is just MSE over all(4) predictions and targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86ME-IEMKE_n"
      },
      "source": [
        "def square_loss(labels, predictions):\n",
        "    return np.mean(np.array([np.sum((l - p) ** 2) for l, p in zip(labels, predictions)]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkPnVBzZKYCS"
      },
      "source": [
        "def accuracy(labels, predictions, err = 1e-5):\n",
        "    return np.mean(np.array([int(abs(np.sum(l - p)) < err) for l, p in zip(labels, predictions)]))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlzGcJWAKvVo"
      },
      "source": [
        "def cost(var, X, Y):\n",
        "    return square_loss(Y, [variational_classifier(var, x) for x in X])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbGwkzO0LBXo"
      },
      "source": [
        "X = input_states\n",
        "Y = Y_transform(output_states)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkWoTGFhnjpY"
      },
      "source": [
        "Setting the learning rate low since the values are sensitive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRW5PSSTLhUY"
      },
      "source": [
        "opt = NesterovMomentumOptimizer(0.01)\n",
        "batch_size = 4 # Since there are only 4 samples"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoscnXyvnqBA"
      },
      "source": [
        "The initiale values of the weights are set to be small random values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqwdsdCRaDhz"
      },
      "source": [
        "np.random.seed(0)\n",
        "num_qubits = 4\n",
        "num_layers = 3\n",
        "var_init = 0.01 * np.random.randn(num_layers, num_qubits, 3)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjujgpVpnv7A"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF0QD5WdMWfi",
        "outputId": "7892bbfa-9801-49a0-d333-c232c73396d9"
      },
      "source": [
        "var = var_init\n",
        "\n",
        "for it in range(200):\n",
        "\n",
        "    # Update the weights by one optimizer step\n",
        "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
        "    X_batch = X[batch_index]\n",
        "    Y_batch = Y[batch_index]\n",
        "    var = opt.step(lambda v: cost(v, X_batch, Y_batch), var)\n",
        "\n",
        "    predictions = [np.sign(variational_classifier(var, x)) for x in X]\n",
        "    acc = accuracy(Y, predictions)\n",
        "    cost_val = cost(var, X, Y)\n",
        "    \n",
        "    if cost_val < 0.6:\n",
        "        break\n",
        "    print(\n",
        "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
        "            it + 1, cost_val, acc\n",
        "        )\n",
        "    )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter:     1 | Cost: 7.9884350 | Accuracy: 0.7500000 \n",
            "Iter:     2 | Cost: 7.9792539 | Accuracy: 0.7500000 \n",
            "Iter:     3 | Cost: 7.9559459 | Accuracy: 0.7500000 \n",
            "Iter:     4 | Cost: 7.8982185 | Accuracy: 0.7500000 \n",
            "Iter:     5 | Cost: 7.7575614 | Accuracy: 0.7500000 \n",
            "Iter:     6 | Cost: 7.4302649 | Accuracy: 0.7500000 \n",
            "Iter:     7 | Cost: 6.7731560 | Accuracy: 0.7500000 \n",
            "Iter:     8 | Cost: 5.7770169 | Accuracy: 0.7500000 \n",
            "Iter:     9 | Cost: 4.7829131 | Accuracy: 0.7500000 \n",
            "Iter:    10 | Cost: 4.1742929 | Accuracy: 0.7500000 \n",
            "Iter:    11 | Cost: 3.9411120 | Accuracy: 0.5000000 \n",
            "Iter:    12 | Cost: 3.8857454 | Accuracy: 0.2500000 \n",
            "Iter:    13 | Cost: 3.8568668 | Accuracy: 0.2500000 \n",
            "Iter:    14 | Cost: 3.7954571 | Accuracy: 0.0000000 \n",
            "Iter:    15 | Cost: 3.6449191 | Accuracy: 0.0000000 \n",
            "Iter:    16 | Cost: 3.4141273 | Accuracy: 0.2500000 \n",
            "Iter:    17 | Cost: 3.1490518 | Accuracy: 0.2500000 \n",
            "Iter:    18 | Cost: 2.9294497 | Accuracy: 0.5000000 \n",
            "Iter:    19 | Cost: 2.8387169 | Accuracy: 0.5000000 \n",
            "Iter:    20 | Cost: 2.8669070 | Accuracy: 0.2500000 \n",
            "Iter:    21 | Cost: 2.9319312 | Accuracy: 0.2500000 \n",
            "Iter:    22 | Cost: 2.9813928 | Accuracy: 0.2500000 \n",
            "Iter:    23 | Cost: 2.9804784 | Accuracy: 0.2500000 \n",
            "Iter:    24 | Cost: 2.9755777 | Accuracy: 0.2500000 \n",
            "Iter:    25 | Cost: 2.9521007 | Accuracy: 0.2500000 \n",
            "Iter:    26 | Cost: 2.9202477 | Accuracy: 0.2500000 \n",
            "Iter:    27 | Cost: 2.8767481 | Accuracy: 0.5000000 \n",
            "Iter:    28 | Cost: 2.8038482 | Accuracy: 0.5000000 \n",
            "Iter:    29 | Cost: 2.7335451 | Accuracy: 0.2500000 \n",
            "Iter:    30 | Cost: 2.6627596 | Accuracy: 0.5000000 \n",
            "Iter:    31 | Cost: 2.6076895 | Accuracy: 0.5000000 \n",
            "Iter:    32 | Cost: 2.5558642 | Accuracy: 0.5000000 \n",
            "Iter:    33 | Cost: 2.5091240 | Accuracy: 0.5000000 \n",
            "Iter:    34 | Cost: 2.4731683 | Accuracy: 0.7500000 \n",
            "Iter:    35 | Cost: 2.4396812 | Accuracy: 0.7500000 \n",
            "Iter:    36 | Cost: 2.4061381 | Accuracy: 0.7500000 \n",
            "Iter:    37 | Cost: 2.3838481 | Accuracy: 1.0000000 \n",
            "Iter:    38 | Cost: 2.3664057 | Accuracy: 0.5000000 \n",
            "Iter:    39 | Cost: 2.3563480 | Accuracy: 0.7500000 \n",
            "Iter:    40 | Cost: 2.3513428 | Accuracy: 0.7500000 \n",
            "Iter:    41 | Cost: 2.3272174 | Accuracy: 0.7500000 \n",
            "Iter:    42 | Cost: 2.2945370 | Accuracy: 0.5000000 \n",
            "Iter:    43 | Cost: 2.2493699 | Accuracy: 0.5000000 \n",
            "Iter:    44 | Cost: 2.1929151 | Accuracy: 0.5000000 \n",
            "Iter:    45 | Cost: 2.1253810 | Accuracy: 0.5000000 \n",
            "Iter:    46 | Cost: 2.0645773 | Accuracy: 0.5000000 \n",
            "Iter:    47 | Cost: 2.0021659 | Accuracy: 0.5000000 \n",
            "Iter:    48 | Cost: 1.9425223 | Accuracy: 0.5000000 \n",
            "Iter:    49 | Cost: 1.8906076 | Accuracy: 0.5000000 \n",
            "Iter:    50 | Cost: 1.8540963 | Accuracy: 0.5000000 \n",
            "Iter:    51 | Cost: 1.8235559 | Accuracy: 0.5000000 \n",
            "Iter:    52 | Cost: 1.7876877 | Accuracy: 0.5000000 \n",
            "Iter:    53 | Cost: 1.7596542 | Accuracy: 0.5000000 \n",
            "Iter:    54 | Cost: 1.7223274 | Accuracy: 0.5000000 \n",
            "Iter:    55 | Cost: 1.6965575 | Accuracy: 0.5000000 \n",
            "Iter:    56 | Cost: 1.6791131 | Accuracy: 0.5000000 \n",
            "Iter:    57 | Cost: 1.6535581 | Accuracy: 0.5000000 \n",
            "Iter:    58 | Cost: 1.6310117 | Accuracy: 0.5000000 \n",
            "Iter:    59 | Cost: 1.6133756 | Accuracy: 0.5000000 \n",
            "Iter:    60 | Cost: 1.5977831 | Accuracy: 0.5000000 \n",
            "Iter:    61 | Cost: 1.5843781 | Accuracy: 0.5000000 \n",
            "Iter:    62 | Cost: 1.5694185 | Accuracy: 0.5000000 \n",
            "Iter:    63 | Cost: 1.5480012 | Accuracy: 0.5000000 \n",
            "Iter:    64 | Cost: 1.5241841 | Accuracy: 0.5000000 \n",
            "Iter:    65 | Cost: 1.5037206 | Accuracy: 0.5000000 \n",
            "Iter:    66 | Cost: 1.4872696 | Accuracy: 0.5000000 \n",
            "Iter:    67 | Cost: 1.4724232 | Accuracy: 0.5000000 \n",
            "Iter:    68 | Cost: 1.4625082 | Accuracy: 0.5000000 \n",
            "Iter:    69 | Cost: 1.4550315 | Accuracy: 0.5000000 \n",
            "Iter:    70 | Cost: 1.4561107 | Accuracy: 0.5000000 \n",
            "Iter:    71 | Cost: 1.4569001 | Accuracy: 0.5000000 \n",
            "Iter:    72 | Cost: 1.4493029 | Accuracy: 0.5000000 \n",
            "Iter:    73 | Cost: 1.4419110 | Accuracy: 0.5000000 \n",
            "Iter:    74 | Cost: 1.4360443 | Accuracy: 0.5000000 \n",
            "Iter:    75 | Cost: 1.4362880 | Accuracy: 0.5000000 \n",
            "Iter:    76 | Cost: 1.4330890 | Accuracy: 0.5000000 \n",
            "Iter:    77 | Cost: 1.4236733 | Accuracy: 0.5000000 \n",
            "Iter:    78 | Cost: 1.4096177 | Accuracy: 0.5000000 \n",
            "Iter:    79 | Cost: 1.3938746 | Accuracy: 0.5000000 \n",
            "Iter:    80 | Cost: 1.3809983 | Accuracy: 0.5000000 \n",
            "Iter:    81 | Cost: 1.3725356 | Accuracy: 0.5000000 \n",
            "Iter:    82 | Cost: 1.3650733 | Accuracy: 0.5000000 \n",
            "Iter:    83 | Cost: 1.3592582 | Accuracy: 0.5000000 \n",
            "Iter:    84 | Cost: 1.3529533 | Accuracy: 0.5000000 \n",
            "Iter:    85 | Cost: 1.3462934 | Accuracy: 0.5000000 \n",
            "Iter:    86 | Cost: 1.3393964 | Accuracy: 0.5000000 \n",
            "Iter:    87 | Cost: 1.3329564 | Accuracy: 0.5000000 \n",
            "Iter:    88 | Cost: 1.3264395 | Accuracy: 0.5000000 \n",
            "Iter:    89 | Cost: 1.3210618 | Accuracy: 0.5000000 \n",
            "Iter:    90 | Cost: 1.3166349 | Accuracy: 0.5000000 \n",
            "Iter:    91 | Cost: 1.3117348 | Accuracy: 0.5000000 \n",
            "Iter:    92 | Cost: 1.3062946 | Accuracy: 0.5000000 \n",
            "Iter:    93 | Cost: 1.2998506 | Accuracy: 0.5000000 \n",
            "Iter:    94 | Cost: 1.2926869 | Accuracy: 0.5000000 \n",
            "Iter:    95 | Cost: 1.2846113 | Accuracy: 0.5000000 \n",
            "Iter:    96 | Cost: 1.2771548 | Accuracy: 0.5000000 \n",
            "Iter:    97 | Cost: 1.2705773 | Accuracy: 0.5000000 \n",
            "Iter:    98 | Cost: 1.2641552 | Accuracy: 0.5000000 \n",
            "Iter:    99 | Cost: 1.2597899 | Accuracy: 0.5000000 \n",
            "Iter:   100 | Cost: 1.2509011 | Accuracy: 0.5000000 \n",
            "Iter:   101 | Cost: 1.2410662 | Accuracy: 0.5000000 \n",
            "Iter:   102 | Cost: 1.2284688 | Accuracy: 0.5000000 \n",
            "Iter:   103 | Cost: 1.2138892 | Accuracy: 0.5000000 \n",
            "Iter:   104 | Cost: 1.2032622 | Accuracy: 0.5000000 \n",
            "Iter:   105 | Cost: 1.1922879 | Accuracy: 0.5000000 \n",
            "Iter:   106 | Cost: 1.1802102 | Accuracy: 0.5000000 \n",
            "Iter:   107 | Cost: 1.1693334 | Accuracy: 0.7500000 \n",
            "Iter:   108 | Cost: 1.1587675 | Accuracy: 0.7500000 \n",
            "Iter:   109 | Cost: 1.1448902 | Accuracy: 0.7500000 \n",
            "Iter:   110 | Cost: 1.1322605 | Accuracy: 0.7500000 \n",
            "Iter:   111 | Cost: 1.1173313 | Accuracy: 0.7500000 \n",
            "Iter:   112 | Cost: 1.1007674 | Accuracy: 0.7500000 \n",
            "Iter:   113 | Cost: 1.0865447 | Accuracy: 0.7500000 \n",
            "Iter:   114 | Cost: 1.0737523 | Accuracy: 0.7500000 \n",
            "Iter:   115 | Cost: 1.0624862 | Accuracy: 0.7500000 \n",
            "Iter:   116 | Cost: 1.0522717 | Accuracy: 0.7500000 \n",
            "Iter:   117 | Cost: 1.0491081 | Accuracy: 0.7500000 \n",
            "Iter:   118 | Cost: 1.0414362 | Accuracy: 0.7500000 \n",
            "Iter:   119 | Cost: 1.0369213 | Accuracy: 0.7500000 \n",
            "Iter:   120 | Cost: 1.0272473 | Accuracy: 0.7500000 \n",
            "Iter:   121 | Cost: 1.0112956 | Accuracy: 0.7500000 \n",
            "Iter:   122 | Cost: 0.9810336 | Accuracy: 0.7500000 \n",
            "Iter:   123 | Cost: 0.9531691 | Accuracy: 0.7500000 \n",
            "Iter:   124 | Cost: 0.9296740 | Accuracy: 0.7500000 \n",
            "Iter:   125 | Cost: 0.9109171 | Accuracy: 0.7500000 \n",
            "Iter:   126 | Cost: 0.8872151 | Accuracy: 0.7500000 \n",
            "Iter:   127 | Cost: 0.8682587 | Accuracy: 0.7500000 \n",
            "Iter:   128 | Cost: 0.8474998 | Accuracy: 0.7500000 \n",
            "Iter:   129 | Cost: 0.8221666 | Accuracy: 1.0000000 \n",
            "Iter:   130 | Cost: 0.7953275 | Accuracy: 1.0000000 \n",
            "Iter:   131 | Cost: 0.7721605 | Accuracy: 1.0000000 \n",
            "Iter:   132 | Cost: 0.7537736 | Accuracy: 1.0000000 \n",
            "Iter:   133 | Cost: 0.7396026 | Accuracy: 1.0000000 \n",
            "Iter:   134 | Cost: 0.7313436 | Accuracy: 1.0000000 \n",
            "Iter:   135 | Cost: 0.7229223 | Accuracy: 1.0000000 \n",
            "Iter:   136 | Cost: 0.7167690 | Accuracy: 1.0000000 \n",
            "Iter:   137 | Cost: 0.7112804 | Accuracy: 1.0000000 \n",
            "Iter:   138 | Cost: 0.7039125 | Accuracy: 1.0000000 \n",
            "Iter:   139 | Cost: 0.6949330 | Accuracy: 1.0000000 \n",
            "Iter:   140 | Cost: 0.6877737 | Accuracy: 1.0000000 \n",
            "Iter:   141 | Cost: 0.6767118 | Accuracy: 1.0000000 \n",
            "Iter:   142 | Cost: 0.6693458 | Accuracy: 1.0000000 \n",
            "Iter:   143 | Cost: 0.6648182 | Accuracy: 1.0000000 \n",
            "Iter:   144 | Cost: 0.6620042 | Accuracy: 1.0000000 \n",
            "Iter:   145 | Cost: 0.6596990 | Accuracy: 1.0000000 \n",
            "Iter:   146 | Cost: 0.6593999 | Accuracy: 1.0000000 \n",
            "Iter:   147 | Cost: 0.6594240 | Accuracy: 1.0000000 \n",
            "Iter:   148 | Cost: 0.6599991 | Accuracy: 1.0000000 \n",
            "Iter:   149 | Cost: 0.6620814 | Accuracy: 1.0000000 \n",
            "Iter:   150 | Cost: 0.6630859 | Accuracy: 1.0000000 \n",
            "Iter:   151 | Cost: 0.6628809 | Accuracy: 1.0000000 \n",
            "Iter:   152 | Cost: 0.6649246 | Accuracy: 1.0000000 \n",
            "Iter:   153 | Cost: 0.6654952 | Accuracy: 1.0000000 \n",
            "Iter:   154 | Cost: 0.6640384 | Accuracy: 1.0000000 \n",
            "Iter:   155 | Cost: 0.6572214 | Accuracy: 1.0000000 \n",
            "Iter:   156 | Cost: 0.6484092 | Accuracy: 1.0000000 \n",
            "Iter:   157 | Cost: 0.6421393 | Accuracy: 1.0000000 \n",
            "Iter:   158 | Cost: 0.6392340 | Accuracy: 1.0000000 \n",
            "Iter:   159 | Cost: 0.6366065 | Accuracy: 1.0000000 \n",
            "Iter:   160 | Cost: 0.6365703 | Accuracy: 1.0000000 \n",
            "Iter:   161 | Cost: 0.6388785 | Accuracy: 1.0000000 \n",
            "Iter:   162 | Cost: 0.6434092 | Accuracy: 1.0000000 \n",
            "Iter:   163 | Cost: 0.6480356 | Accuracy: 1.0000000 \n",
            "Iter:   164 | Cost: 0.6557725 | Accuracy: 1.0000000 \n",
            "Iter:   165 | Cost: 0.6578495 | Accuracy: 1.0000000 \n",
            "Iter:   166 | Cost: 0.6582789 | Accuracy: 1.0000000 \n",
            "Iter:   167 | Cost: 0.6568680 | Accuracy: 1.0000000 \n",
            "Iter:   168 | Cost: 0.6614930 | Accuracy: 1.0000000 \n",
            "Iter:   169 | Cost: 0.6671701 | Accuracy: 1.0000000 \n",
            "Iter:   170 | Cost: 0.6660400 | Accuracy: 1.0000000 \n",
            "Iter:   171 | Cost: 0.6708055 | Accuracy: 1.0000000 \n",
            "Iter:   172 | Cost: 0.6718979 | Accuracy: 1.0000000 \n",
            "Iter:   173 | Cost: 0.6696649 | Accuracy: 1.0000000 \n",
            "Iter:   174 | Cost: 0.6690611 | Accuracy: 1.0000000 \n",
            "Iter:   175 | Cost: 0.6646276 | Accuracy: 1.0000000 \n",
            "Iter:   176 | Cost: 0.6578431 | Accuracy: 1.0000000 \n",
            "Iter:   177 | Cost: 0.6507624 | Accuracy: 1.0000000 \n",
            "Iter:   178 | Cost: 0.6411132 | Accuracy: 1.0000000 \n",
            "Iter:   179 | Cost: 0.6335452 | Accuracy: 1.0000000 \n",
            "Iter:   180 | Cost: 0.6274988 | Accuracy: 1.0000000 \n",
            "Iter:   181 | Cost: 0.6247541 | Accuracy: 1.0000000 \n",
            "Iter:   182 | Cost: 0.6248543 | Accuracy: 1.0000000 \n",
            "Iter:   183 | Cost: 0.6256717 | Accuracy: 1.0000000 \n",
            "Iter:   184 | Cost: 0.6271498 | Accuracy: 1.0000000 \n",
            "Iter:   185 | Cost: 0.6272005 | Accuracy: 1.0000000 \n",
            "Iter:   186 | Cost: 0.6258874 | Accuracy: 1.0000000 \n",
            "Iter:   187 | Cost: 0.6249042 | Accuracy: 1.0000000 \n",
            "Iter:   188 | Cost: 0.6234753 | Accuracy: 1.0000000 \n",
            "Iter:   189 | Cost: 0.6206969 | Accuracy: 1.0000000 \n",
            "Iter:   190 | Cost: 0.6197882 | Accuracy: 1.0000000 \n",
            "Iter:   191 | Cost: 0.6195409 | Accuracy: 1.0000000 \n",
            "Iter:   192 | Cost: 0.6221929 | Accuracy: 1.0000000 \n",
            "Iter:   193 | Cost: 0.6267451 | Accuracy: 1.0000000 \n",
            "Iter:   194 | Cost: 0.6326519 | Accuracy: 1.0000000 \n",
            "Iter:   195 | Cost: 0.6378136 | Accuracy: 1.0000000 \n",
            "Iter:   196 | Cost: 0.6469099 | Accuracy: 1.0000000 \n",
            "Iter:   197 | Cost: 0.6541159 | Accuracy: 1.0000000 \n",
            "Iter:   198 | Cost: 0.6680192 | Accuracy: 1.0000000 \n",
            "Iter:   199 | Cost: 0.6818578 | Accuracy: 1.0000000 \n",
            "Iter:   200 | Cost: 0.6856744 | Accuracy: 1.0000000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z3547QEUy-N"
      },
      "source": [
        "def to_bit(x):\n",
        "    l = list(\"{0:b}\".format(x))\n",
        "    l = [int(x) for x in l]\n",
        "    while len(l) != 4:\n",
        "        l.insert(0, 0)\n",
        "    return l"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BssJJDkRXFG3"
      },
      "source": [
        "def to_num(x):\n",
        "    x = x[::-1]\n",
        "    return sum([(x[i] * (2**i)) for i in range(len(x))])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PsMuW38Wvru"
      },
      "source": [
        "def predict(x):\n",
        "    ''' Assuming that the input is np.array of 4 bits(0 or 1)'''\n",
        "    y = np.sign(variational_classifier(var, x))\n",
        "    y = np.array([int(l == 1) for l in y]) # converting it back to bits\n",
        "    return y"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gradtwlTMsv_"
      },
      "source": [
        "x = list(range(16))\n",
        "y = []\n",
        "for i in x:\n",
        "    j = predict(to_bit(i))\n",
        "    j = j.numpy()\n",
        "    y.append(to_num(j))\n",
        "\n",
        "x_actual = [to_num(i) for i in input_states]\n",
        "y_actual = [to_num(i) for i in output_states]\n",
        "\n",
        "labels = ['|' + ''.join([str(l)  for l in to_bit(i)]) + '>' for i in x]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FY85gBRjGnL"
      },
      "source": [
        "## Plotting the classifier output\n",
        "\n",
        "We convert the bits into integer based on big endian conversion. This will allow us to plot the expected answer and the prediction for the values that haven't been trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_n6MGEw8OIe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "37001af7-ae42-4ef7-dcba-908828605906"
      },
      "source": [
        "f, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_yticks(x)\n",
        "ax.set_yticklabels(labels)\n",
        "plt.scatter(x, y, color='yellow', alpha=0.8, s=80)\n",
        "plt.scatter(x_actual, y_actual, color='black', alpha=1, s=20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f9fbf5b13d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}